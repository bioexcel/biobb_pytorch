<!DOCTYPE html>
<html>
   <head>
      <title>biobb_pytorch/mdae/loss/elbo.py - flake8 annotated source</title>
      <meta http-equiv="Content-Type" value="text/html; charset=UTF-8">
      <link rel="stylesheet" href="styles.css">
   </head>
   <body>
      <div id="masthead" class="sev-2"></div>
      <div id="page">
         <h1>
            <a href="biobb_pytorch.mdae.loss.elbo.report.html">
               <img src="back.svg" alt="&#x2B05;">
               biobb_pytorch/mdae/loss/elbo.py source
            </a>
         </h1>

         <div id="doc">
            <div id="l1"
               class="code sev- "><tt><i>1</i> <span class="ch">#!/usr/bin/env python</span></tt>
            </div>
            <div id="l2"
               class="code sev- "><tt><i>2</i> &nbsp;</tt>
            </div>
            <div id="l3"
               class="code sev- "><tt><i>3</i> <span class="c1"># =============================================================================</span></tt>
            </div>
            <div id="l4"
               class="code sev- "><tt><i>4</i> <span class="c1"># MODULE DOCSTRING</span></tt>
            </div>
            <div id="l5"
               class="code sev- "><tt><i>5</i> <span class="c1"># =============================================================================</span></tt>
            </div>
            <div id="l6"
               class="code sev- "><tt><i>6</i> &nbsp;</tt>
            </div>
            <div id="l7"
               class="code sev- "><tt><i>7</i> <span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l8"
               class="code sev- "><tt><i>8</i> <span class="sd">Evidence Lower BOund (ELBO) loss functions used to train variational Autoencoders.</span></tt>
            </div>
            <div id="l9"
               class="code sev- "><tt><i>9</i> <span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l10"
               class="code sev- "><tt><i>10</i> &nbsp;</tt>
            </div>
            <div id="l11"
               class="code sev- "><tt><i>11</i> <span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ELBOGaussiansLoss&quot;</span><span class="p">,</span> <span class="s2">&quot;elbo_gaussians_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;ELBOLoss&quot;</span><span class="p">,</span> <span class="s2">&quot;ELBOGaussianMixtureLoss&quot;</span><span class="p">]</span></tt>
            </div>
            <div id="l12"
               class="code sev- "><tt><i>12</i> &nbsp;</tt>
            </div>
            <div id="l13"
               class="code sev- "><tt><i>13</i> &nbsp;</tt>
            </div>
            <div id="l14"
               class="code sev- "><tt><i>14</i> <span class="c1"># =============================================================================</span></tt>
            </div>
            <div id="l15"
               class="code sev- "><tt><i>15</i> <span class="c1"># GLOBAL IMPORTS</span></tt>
            </div>
            <div id="l16"
               class="code sev- "><tt><i>16</i> <span class="c1"># =============================================================================</span></tt>
            </div>
            <div id="l17"
               class="code sev- "><tt><i>17</i> &nbsp;</tt>
            </div>
            <div id="l18"
               class="code sev- "><tt><i>18</i> <span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span></tt>
            </div>
            <div id="l19"
               class="code sev- "><tt><i>19</i> <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span></tt>
            </div>
            <div id="l20"
               class="code sev- "><tt><i>20</i> <span class="kn">import</span><span class="w"> </span><span class="nn">math</span></tt>
            </div>
            <div id="l21"
               class="code sev- "><tt><i>21</i> <span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span></tt>
            </div>
            <div id="l22"
               class="code sev- "><tt><i>22</i> <span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span></tt>
            </div>
            <div id="l23"
               class="code sev- "><tt><i>23</i> <span class="kn">from</span><span class="w"> </span><span class="nn">mlcolvar.core.loss.mse</span><span class="w"> </span><span class="kn">import</span> <span class="n">mse_loss</span></tt>
            </div>
            <div id="l24"
               class="code sev- "><tt><i>24</i> &nbsp;</tt>
            </div>
            <div id="l25"
               class="code sev- "><tt><i>25</i> &nbsp;</tt>
            </div>
            <div id="l26"
               class="code sev- "><tt><i>26</i> <span class="c1"># =============================================================================</span></tt>
            </div>
            <div id="l27"
               class="code sev- "><tt><i>27</i> <span class="c1"># LOSS FUNCTIONS</span></tt>
            </div>
            <div id="l28"
               class="code sev- "><tt><i>28</i> <span class="c1"># =============================================================================</span></tt>
            </div>
            <div id="l29"
               class="code sev- "><tt><i>29</i> &nbsp;</tt>
            </div>
            <div id="l30"
               class="code sev- "><tt><i>30</i> &nbsp;</tt>
            </div>
            <div id="l31"
               class="code sev- "><tt><i>31</i> <span class="k">class</span><span class="w"> </span><span class="nc">ELBOGaussiansLoss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span></tt>
            </div>
            <div id="l32"
               class="code sev- "><tt><i>32</i> <span class="w">    </span><span class="sd">&quot;&quot;&quot;ELBO loss function assuming the latent and reconstruction distributions are Gaussian.</span></tt>
            </div>
            <div id="l33"
               class="code sev- "><tt><i>33</i> &nbsp;</tt>
            </div>
            <div id="l34"
               class="code sev- "><tt><i>34</i> <span class="sd">    The ELBO uses the MSE as the reconstruction loss (i.e., assumes that the</span></tt>
            </div>
            <div id="l35"
               class="code sev- "><tt><i>35</i> <span class="sd">    decoder outputs the mean of a Gaussian distribution with variance 1), and</span></tt>
            </div>
            <div id="l36"
               class="code sev- "><tt><i>36</i> <span class="sd">    the KL divergence between two normal distributions ``N(mean, var)`` and</span></tt>
            </div>
            <div id="l37"
               class="code sev- "><tt><i>37</i> <span class="sd">    ``N(0, 1)``, where ``mean`` and ``var`` are the output of the encoder.</span></tt>
            </div>
            <div id="l38"
               class="code sev- "><tt><i>38</i> <span class="sd">    &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l39"
               class="code sev- "><tt><i>39</i> &nbsp;</tt>
            </div>
            <div id="l40"
               class="code sev- "><tt><i>40</i>     <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span></tt>
            </div>
            <div id="l41"
               class="code sev- "><tt><i>41</i>         <span class="bp">self</span><span class="p">,</span></tt>
            </div>
            <div id="l42"
               class="code sev- "><tt><i>42</i>         <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l43"
               class="code sev- "><tt><i>43</i>         <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l44"
               class="code sev- "><tt><i>44</i>         <span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l45"
               class="code sev- "><tt><i>45</i>         <span class="n">log_variance</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l46"
               class="code sev- "><tt><i>46</i>         <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span></tt>
            </div>
            <div id="l47"
               class="code sev- "><tt><i>47</i>     <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span></tt>
            </div>
            <div id="l48"
               class="code sev- "><tt><i>48</i> <span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the value of the loss function.</span></tt>
            </div>
            <div id="l49"
               class="code sev- "><tt><i>49</i> &nbsp;</tt>
            </div>
            <div id="l50"
               class="code sev- "><tt><i>50</i> <span class="sd">        Parameters</span></tt>
            </div>
            <div id="l51"
               class="code sev- "><tt><i>51</i> <span class="sd">        ----------</span></tt>
            </div>
            <div id="l52"
               class="code sev- "><tt><i>52</i> <span class="sd">        target : torch.Tensor</span></tt>
            </div>
            <div id="l53"
               class="code sev- "><tt><i>53</i> <span class="sd">            Shape ``(n_batches, in_features)``. Data points (e.g. input of encoder</span></tt>
            </div>
            <div id="l54"
               class="code sev- "><tt><i>54</i> <span class="sd">            or time-lagged features).</span></tt>
            </div>
            <div id="l55"
               class="code sev- "><tt><i>55</i> <span class="sd">        output : torch.Tensor</span></tt>
            </div>
            <div id="l56"
               class="code sev- "><tt><i>56</i> <span class="sd">            Shape ``(n_batches, in_features)``. Output of the decoder.</span></tt>
            </div>
            <div id="l57"
               class="code sev- "><tt><i>57</i> <span class="sd">        mean : torch.Tensor</span></tt>
            </div>
            <div id="l58"
               class="code sev- "><tt><i>58</i> <span class="sd">            Shape ``(n_batches, latent_features)``. The means of the Gaussian</span></tt>
            </div>
            <div id="l59"
               class="code sev- "><tt><i>59</i> <span class="sd">            distributions associated to the inputs.</span></tt>
            </div>
            <div id="l60"
               class="code sev- "><tt><i>60</i> <span class="sd">        log_variance : torch.Tensor</span></tt>
            </div>
            <div id="l61"
               class="code sev- "><tt><i>61</i> <span class="sd">            Shape ``(n_batches, latent_features)``. The logarithm of the variances</span></tt>
            </div>
            <div id="l62"
               class="code sev- "><tt><i>62</i> <span class="sd">            of the Gaussian distributions associated to the inputs.</span></tt>
            </div>
            <div id="l63"
               class="code sev- "><tt><i>63</i> <span class="sd">        weights : torch.Tensor, optional</span></tt>
            </div>
            <div id="l64"
               class="code sev- "><tt><i>64</i> <span class="sd">            Shape ``(n_batches,)`` or ``(n_batches,1)``. If given, the average over</span></tt>
            </div>
            <div id="l65"
               class="code sev- "><tt><i>65</i> <span class="sd">            batches is weighted. The default (``None``) is unweighted.</span></tt>
            </div>
            <div id="l66"
               class="code sev- "><tt><i>66</i> &nbsp;</tt>
            </div>
            <div id="l67"
               class="code sev- "><tt><i>67</i> <span class="sd">        Returns</span></tt>
            </div>
            <div id="l68"
               class="code sev- "><tt><i>68</i> <span class="sd">        -------</span></tt>
            </div>
            <div id="l69"
               class="code sev- "><tt><i>69</i> <span class="sd">        loss: torch.Tensor</span></tt>
            </div>
            <div id="l70"
               class="code sev- "><tt><i>70</i> <span class="sd">            The value of the loss function.</span></tt>
            </div>
            <div id="l71"
               class="code sev- "><tt><i>71</i> <span class="sd">        &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l72"
               class="code sev- "><tt><i>72</i>         <span class="k">return</span> <span class="n">elbo_gaussians_loss</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">log_variance</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></tt>
            </div>
            <div id="l73"
               class="code sev- "><tt><i>73</i> &nbsp;</tt>
            </div>
            <div id="l74"
               class="code sev- "><tt><i>74</i> &nbsp;</tt>
            </div>
            <div id="l75"
               class="code sev- "><tt><i>75</i> <span class="k">def</span><span class="w"> </span><span class="nf">elbo_gaussians_loss</span><span class="p">(</span></tt>
            </div>
            <div id="l76"
               class="code sev- "><tt><i>76</i>     <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l77"
               class="code sev- "><tt><i>77</i>     <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l78"
               class="code sev- "><tt><i>78</i>     <span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l79"
               class="code sev- "><tt><i>79</i>     <span class="n">log_variance</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l80"
               class="code sev- "><tt><i>80</i>     <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span></tt>
            </div>
            <div id="l81"
               class="code sev- "><tt><i>81</i> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span></tt>
            </div>
            <div id="l82"
               class="code sev- "><tt><i>82</i> <span class="w">    </span><span class="sd">&quot;&quot;&quot;ELBO loss function assuming the latent and reconstruction distributions are Gaussian.</span></tt>
            </div>
            <div id="l83"
               class="code sev- "><tt><i>83</i> &nbsp;</tt>
            </div>
            <div id="l84"
               class="code sev- "><tt><i>84</i> <span class="sd">    The ELBO uses the MSE as the reconstruction loss (i.e., assumes that the</span></tt>
            </div>
            <div id="l85"
               class="code sev- "><tt><i>85</i> <span class="sd">    decoder outputs the mean of a Gaussian distribution with variance 1), and</span></tt>
            </div>
            <div id="l86"
               class="code sev- "><tt><i>86</i> <span class="sd">    the KL divergence between two normal distributions ``N(mean, var)`` and</span></tt>
            </div>
            <div id="l87"
               class="code sev- "><tt><i>87</i> <span class="sd">    ``N(0, 1)``, where ``mean`` and ``var`` are the output of the encoder.</span></tt>
            </div>
            <div id="l88"
               class="code sev- "><tt><i>88</i> &nbsp;</tt>
            </div>
            <div id="l89"
               class="code sev- "><tt><i>89</i> <span class="sd">    Parameters</span></tt>
            </div>
            <div id="l90"
               class="code sev- "><tt><i>90</i> <span class="sd">    ----------</span></tt>
            </div>
            <div id="l91"
               class="code sev- "><tt><i>91</i> <span class="sd">    target : torch.Tensor</span></tt>
            </div>
            <div id="l92"
               class="code sev- "><tt><i>92</i> <span class="sd">        Shape ``(n_batches, in_features)``. Data points (e.g. input of encoder</span></tt>
            </div>
            <div id="l93"
               class="code sev- "><tt><i>93</i> <span class="sd">        or time-lagged features).</span></tt>
            </div>
            <div id="l94"
               class="code sev- "><tt><i>94</i> <span class="sd">    output : torch.Tensor</span></tt>
            </div>
            <div id="l95"
               class="code sev- "><tt><i>95</i> <span class="sd">        Shape ``(n_batches, in_features)``. Output of the decoder.</span></tt>
            </div>
            <div id="l96"
               class="code sev- "><tt><i>96</i> <span class="sd">    mean : torch.Tensor</span></tt>
            </div>
            <div id="l97"
               class="code sev- "><tt><i>97</i> <span class="sd">        Shape ``(n_batches, latent_features)``. The means of the Gaussian</span></tt>
            </div>
            <div id="l98"
               class="code sev- "><tt><i>98</i> <span class="sd">        distributions associated to the inputs.</span></tt>
            </div>
            <div id="l99"
               class="code sev- "><tt><i>99</i> <span class="sd">    log_variance : torch.Tensor</span></tt>
            </div>
            <div id="l100"
               class="code sev- "><tt><i>100</i> <span class="sd">        Shape ``(n_batches, latent_features)``. The logarithm of the variances</span></tt>
            </div>
            <div id="l101"
               class="code sev- "><tt><i>101</i> <span class="sd">        of the Gaussian distributions associated to the inputs.</span></tt>
            </div>
            <div id="l102"
               class="code sev- "><tt><i>102</i> <span class="sd">    weights : torch.Tensor, optional</span></tt>
            </div>
            <div id="l103"
               class="code sev- "><tt><i>103</i> <span class="sd">        Shape ``(n_batches,)`` or ``(n_batches,1)``. If given, the average over</span></tt>
            </div>
            <div id="l104"
               class="code sev- "><tt><i>104</i> <span class="sd">        batches is weighted. The default (``None``) is unweighted.</span></tt>
            </div>
            <div id="l105"
               class="code sev- "><tt><i>105</i> &nbsp;</tt>
            </div>
            <div id="l106"
               class="code sev- "><tt><i>106</i> <span class="sd">    Returns</span></tt>
            </div>
            <div id="l107"
               class="code sev- "><tt><i>107</i> <span class="sd">    -------</span></tt>
            </div>
            <div id="l108"
               class="code sev- "><tt><i>108</i> <span class="sd">    loss: torch.Tensor</span></tt>
            </div>
            <div id="l109"
               class="code sev- "><tt><i>109</i> <span class="sd">        The value of the loss function.</span></tt>
            </div>
            <div id="l110"
               class="code sev- "><tt><i>110</i> <span class="sd">    &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l111"
               class="code sev- "><tt><i>111</i>     <span class="c1"># KL divergence between N(mean, variance) and N(0, 1).</span></tt>
            </div>
            <div id="l112"
               class="code sev- "><tt><i>112</i>     <span class="c1"># See https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians</span></tt>
            </div>
            <div id="l113"
               class="code sev- "><tt><i>113</i>     <span class="n">kl</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">log_variance</span> <span class="o">-</span> <span class="n">log_variance</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">-</span> <span class="n">mean</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></tt>
            </div>
            <div id="l114"
               class="code sev- "><tt><i>114</i> &nbsp;</tt>
            </div>
            <div id="l115"
               class="code sev- "><tt><i>115</i>     <span class="c1"># Weighted mean over batches.</span></tt>
            </div>
            <div id="l116"
               class="code sev- "><tt><i>116</i>     <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span></tt>
            </div>
            <div id="l117"
               class="code sev- "><tt><i>117</i>         <span class="n">kl</span> <span class="o">=</span> <span class="n">kl</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></tt>
            </div>
            <div id="l118"
               class="code sev- "><tt><i>118</i>     <span class="k">else</span><span class="p">:</span></tt>
            </div>
            <div id="l119"
               class="code sev- "><tt><i>119</i>         <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></tt>
            </div>
            <div id="l120"
               class="code sev- "><tt><i>120</i>         <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">kl</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span></tt>
            </div>
            <div id="l121"
               class="code sev- "><tt><i>121</i>             <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span></tt>
            </div>
            <div id="l122"
               class="code sev- "><tt><i>122</i>                 <span class="sa">f</span><span class="s2">&quot;weights should be a tensor of shape (n_batches,) or (n_batches,1), not </span><span class="si">{</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span></tt>
            </div>
            <div id="l123"
               class="code sev- "><tt><i>123</i>             <span class="p">)</span></tt>
            </div>
            <div id="l124"
               class="code sev- "><tt><i>124</i>         <span class="n">kl</span> <span class="o">=</span> <span class="p">(</span><span class="n">kl</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></tt>
            </div>
            <div id="l125"
               class="code sev- "><tt><i>125</i> &nbsp;</tt>
            </div>
            <div id="l126"
               class="code sev- "><tt><i>126</i>     <span class="c1"># Reconstruction loss.</span></tt>
            </div>
            <div id="l127"
               class="code sev- "><tt><i>127</i>     <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span></tt>
            </div>
            <div id="l128"
               class="code sev- "><tt><i>128</i> &nbsp;</tt>
            </div>
            <div id="l129"
               class="code sev- "><tt><i>129</i>     <span class="k">return</span> <span class="n">reconstruction</span> <span class="o">+</span> <span class="n">kl</span></tt>
            </div>
            <div id="l130"
               class="code sev- "><tt><i>130</i> &nbsp;</tt>
            </div>
            <div id="l131"
               class="code sev- "><tt><i>131</i> &nbsp;</tt>
            </div>
            <div id="l132"
               class="code sev- "><tt><i>132</i> <span class="k">class</span><span class="w"> </span><span class="nc">ELBOLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span></tt>
            </div>
            <div id="l133"
               class="code sev- "><tt><i>133</i> <span class="w">    </span><span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l134"
               class="code sev- "><tt><i>134</i> <span class="sd">    Variational Autoencoder ELBO loss function.</span></tt>
            </div>
            <div id="l135"
               class="code sev- "><tt><i>135</i> &nbsp;</tt>
            </div>
            <div id="l136"
               class="code sev- "><tt><i>136</i> <span class="sd">    Implements the evidence lower bound (ELBO) objective:</span></tt>
            </div>
            <div id="l137"
               class="code sev- "><tt><i>137</i> <span class="sd">        L = reconstruction_loss + beta * KL_divergence</span></tt>
            </div>
            <div id="l138"
               class="code sev- "><tt><i>138</i> &nbsp;</tt>
            </div>
            <div id="l139"
               class="code sev- "><tt><i>139</i> <span class="sd">    Reconstruction loss options:</span></tt>
            </div>
            <div id="l140"
               class="code sev- "><tt><i>140</i> <span class="sd">      - Mean-squared error (MSE) -&gt; assumes Gaussian decoder with unit variance</span></tt>
            </div>
            <div id="l141"
               class="code sev- "><tt><i>141</i> <span class="sd">      - Binary cross-entropy (BCE) -&gt; assumes Bernoulli decoder</span></tt>
            </div>
            <div id="l142"
               class="code sev- "><tt><i>142</i> &nbsp;</tt>
            </div>
            <div id="l143"
               class="code sev- "><tt><i>143</i> <span class="sd">    KL divergence is computed analytically between the approximate posterior</span></tt>
            </div>
            <div id="l144"
               class="code sev- "><tt><i>144</i> <span class="sd">    q(z|x) = N(mu, diag(var)) and the prior p(z) = N(0, I):</span></tt>
            </div>
            <div id="l145"
               class="code sev- "><tt><i>145</i> <span class="sd">        KL(q||p) = -0.5 * sum(1 + log(var) - mu^2 - var)</span></tt>
            </div>
            <div id="l146"
               class="code sev- "><tt><i>146</i> &nbsp;</tt>
            </div>
            <div id="l147"
               class="code sev- "><tt><i>147</i> <span class="sd">    Parameters</span></tt>
            </div>
            <div id="l148"
               class="code sev- "><tt><i>148</i> <span class="sd">    ----------</span></tt>
            </div>
            <div id="l149"
               class="code sev- "><tt><i>149</i> <span class="sd">    beta : float, default=1.0</span></tt>
            </div>
            <div id="l150"
               class="code sev- "><tt><i>150</i> <span class="sd">        Scaling factor for the KL divergence term (beta-VAE).</span></tt>
            </div>
            <div id="l151"
               class="code sev- "><tt><i>151</i> <span class="sd">    loss_type : {&#39;mse&#39;, &#39;bce&#39;}, default=&#39;mse&#39;</span></tt>
            </div>
            <div id="l152"
               class="code sev- "><tt><i>152</i> <span class="sd">        Type of reconstruction loss:</span></tt>
            </div>
            <div id="l153"
               class="code sev- "><tt><i>153</i> <span class="sd">        - &#39;mse&#39;: use mean squared error</span></tt>
            </div>
            <div id="l154"
               class="code sev- "><tt><i>154</i> <span class="sd">        - &#39;bce&#39;: use binary cross-entropy</span></tt>
            </div>
            <div id="l155"
               class="code sev- "><tt><i>155</i> <span class="sd">    reduction : {&#39;sum&#39;, &#39;mean&#39;, &#39;none&#39;}, default=&#39;sum&#39;</span></tt>
            </div>
            <div id="l156"
               class="code sev- "><tt><i>156</i> <span class="sd">        How to reduce the reconstruction loss over elements:</span></tt>
            </div>
            <div id="l157"
               class="code sev- "><tt><i>157</i> <span class="sd">        - &#39;sum&#39;: sum over all elements</span></tt>
            </div>
            <div id="l158"
               class="code sev- "><tt><i>158</i> <span class="sd">        - &#39;mean&#39;: average over all elements</span></tt>
            </div>
            <div id="l159"
               class="code sev- "><tt><i>159</i> <span class="sd">        - &#39;none&#39;: no reduction (returns per-element loss)</span></tt>
            </div>
            <div id="l160"
               class="code sev- "><tt><i>160</i> <span class="sd">    &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l161"
               class="code sev- "><tt><i>161</i> &nbsp;</tt>
            </div>
            <div id="l162"
               class="code sev- "><tt><i>162</i>     <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span></tt>
            </div>
            <div id="l163"
               class="code sev- "><tt><i>163</i>         <span class="bp">self</span><span class="p">,</span></tt>
            </div>
            <div id="l164"
               class="code sev- "><tt><i>164</i>         <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span></tt>
            </div>
            <div id="l165"
               class="code sev- "><tt><i>165</i>         <span class="n">reconstruction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mse&#39;</span><span class="p">,</span></tt>
            </div>
            <div id="l166"
               class="code sev- "><tt><i>166</i>         <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span></tt>
            </div>
            <div id="l167"
               class="code sev- "><tt><i>167</i>     <span class="p">):</span></tt>
            </div>
            <div id="l168"
               class="code sev- "><tt><i>168</i>         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span></tt>
            </div>
            <div id="l169"
               class="code sev- "><tt><i>169</i>         <span class="k">if</span> <span class="n">reconstruction</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="s1">&#39;bce&#39;</span><span class="p">}:</span></tt>
            </div>
            <div id="l170"
               class="code sev- "><tt><i>170</i>             <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported reconstruction &#39;</span><span class="si">{</span><span class="n">reconstruction</span><span class="si">}</span><span class="s2">&#39;, choose &#39;mse&#39; or &#39;bce&#39;.&quot;</span><span class="p">)</span></tt>
            </div>
            <div id="l171"
               class="code sev- "><tt><i>171</i>         <span class="k">if</span> <span class="n">reduction</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">}:</span></tt>
            </div>
            <div id="l172"
               class="code sev- "><tt><i>172</i>             <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported reduction &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39;, choose &#39;sum&#39;, &#39;mean&#39;, or &#39;none&#39;.&quot;</span><span class="p">)</span></tt>
            </div>
            <div id="l173"
               class="code sev- "><tt><i>173</i> &nbsp;</tt>
            </div>
            <div id="l174"
               class="code sev- "><tt><i>174</i>         <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span></tt>
            </div>
            <div id="l175"
               class="code sev- "><tt><i>175</i>         <span class="bp">self</span><span class="o">.</span><span class="n">reconstruction</span> <span class="o">=</span> <span class="n">reconstruction</span></tt>
            </div>
            <div id="l176"
               class="code sev- "><tt><i>176</i>         <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">reduction</span></tt>
            </div>
            <div id="l177"
               class="code sev- "><tt><i>177</i> &nbsp;</tt>
            </div>
            <div id="l178"
               class="code sev- "><tt><i>178</i>     <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span></tt>
            </div>
            <div id="l179"
               class="code sev- "><tt><i>179</i>         <span class="bp">self</span><span class="p">,</span></tt>
            </div>
            <div id="l180"
               class="code sev- "><tt><i>180</i>         <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l181"
               class="code sev- "><tt><i>181</i>         <span class="n">recon_x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l182"
               class="code sev- "><tt><i>182</i>         <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l183"
               class="code sev- "><tt><i>183</i>         <span class="n">log_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></tt>
            </div>
            <div id="l184"
               class="code sev- "><tt><i>184</i>     <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span></tt>
            </div>
            <div id="l185"
               class="code sev- "><tt><i>185</i> <span class="w">        </span><span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l186"
               class="code sev- "><tt><i>186</i> <span class="sd">        Compute the combined ELBO loss.</span></tt>
            </div>
            <div id="l187"
               class="code sev- "><tt><i>187</i> &nbsp;</tt>
            </div>
            <div id="l188"
               class="code sev- "><tt><i>188</i> <span class="sd">        Parameters</span></tt>
            </div>
            <div id="l189"
               class="code sev- "><tt><i>189</i> <span class="sd">        ----------</span></tt>
            </div>
            <div id="l190"
               class="code sev- "><tt><i>190</i> <span class="sd">        x : Tensor</span></tt>
            </div>
            <div id="l191"
               class="code sev- "><tt><i>191</i> <span class="sd">            Original input tensor (shape: [batch_size, ...]).</span></tt>
            </div>
            <div id="l192"
               class="code sev- "><tt><i>192</i> <span class="sd">        recon_x : Tensor</span></tt>
            </div>
            <div id="l193"
               class="code sev- "><tt><i>193</i> <span class="sd">            Reconstructed output tensor (same shape as x).</span></tt>
            </div>
            <div id="l194"
               class="code sev- "><tt><i>194</i> <span class="sd">        mu : Tensor</span></tt>
            </div>
            <div id="l195"
               class="code sev- "><tt><i>195</i> <span class="sd">            Mean of the approximate posterior q(z|x) (shape: [batch_size, latent_dim]).</span></tt>
            </div>
            <div id="l196"
               class="code sev- "><tt><i>196</i> <span class="sd">        log_var : Tensor</span></tt>
            </div>
            <div id="l197"
               class="code sev- "><tt><i>197</i> <span class="sd">            Log-variance of q(z|x) (same shape as mu).</span></tt>
            </div>
            <div id="l198"
               class="code sev- "><tt><i>198</i> &nbsp;</tt>
            </div>
            <div id="l199"
               class="code sev- "><tt><i>199</i> <span class="sd">        Returns</span></tt>
            </div>
            <div id="l200"
               class="code sev- "><tt><i>200</i> <span class="sd">        -------</span></tt>
            </div>
            <div id="l201"
               class="code sev- "><tt><i>201</i> <span class="sd">        loss : Tensor</span></tt>
            </div>
            <div id="l202"
               class="code sev- "><tt><i>202</i> <span class="sd">            Scalar loss (if reduction!=&#39;none&#39;) or tensor of per-element losses.</span></tt>
            </div>
            <div id="l203"
               class="code sev- "><tt><i>203</i> <span class="sd">        &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l204"
               class="code sev- "><tt><i>204</i>         <span class="c1"># Reconstruction loss</span></tt>
            </div>
            <div id="l205"
               class="code sev- "><tt><i>205</i>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reconstruction</span> <span class="o">==</span> <span class="s1">&#39;bce&#39;</span><span class="p">:</span></tt>
            </div>
            <div id="l206"
               class="code sev- "><tt><i>206</i>             <span class="c1"># For binary data, use BCE</span></tt>
            </div>
            <div id="l207"
               class="code sev- "><tt><i>207</i>             <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span></tt>
            </div>
            <div id="l208"
               class="code sev- "><tt><i>208</i>                 <span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span></tt>
            </div>
            <div id="l209"
               class="code sev- "><tt><i>209</i>             <span class="p">)</span></tt>
            </div>
            <div id="l210"
               class="code sev- "><tt><i>210</i>         <span class="k">else</span><span class="p">:</span></tt>
            </div>
            <div id="l211"
               class="code sev- "><tt><i>211</i>             <span class="c1"># For continuous data, use MSE</span></tt>
            </div>
            <div id="l212"
               class="code sev- "><tt><i>212</i>             <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span></tt>
            </div>
            <div id="l213"
               class="code sev- "><tt><i>213</i>                 <span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span></tt>
            </div>
            <div id="l214"
               class="code sev- "><tt><i>214</i>             <span class="p">)</span></tt>
            </div>
            <div id="l215"
               class="code sev- "><tt><i>215</i> &nbsp;</tt>
            </div>
            <div id="l216"
               class="code sev- "><tt><i>216</i>         <span class="c1"># Analytic KL divergence between N(mu, var) and N(0, I)</span></tt>
            </div>
            <div id="l217"
               class="code sev- "><tt><i>217</i>         <span class="c1"># var = exp(log_var)</span></tt>
            </div>
            <div id="l218"
               class="code sev- "><tt><i>218</i>         <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_var</span><span class="p">)</span></tt>
            </div>
            <div id="l219"
               class="code sev- "><tt><i>219</i>         <span class="n">kl_div</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span></tt>
            </div>
            <div id="l220"
               class="code sev- "><tt><i>220</i>             <span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">var</span><span class="p">,</span></tt>
            </div>
            <div id="l221"
               class="code sev- "><tt><i>221</i>             <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>  <span class="c1"># sum over latent dimension for each sample</span></tt>
            </div>
            <div id="l222"
               class="code sev- "><tt><i>222</i>         <span class="p">)</span></tt>
            </div>
            <div id="l223"
               class="code sev- "><tt><i>223</i> &nbsp;</tt>
            </div>
            <div id="l224"
               class="code sev- "><tt><i>224</i>         <span class="c1"># Combine terms: sum or mean over batch</span></tt>
            </div>
            <div id="l225"
               class="code sev- "><tt><i>225</i>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span></tt>
            </div>
            <div id="l226"
               class="code sev- "><tt><i>226</i>             <span class="n">kl_div</span> <span class="o">=</span> <span class="n">kl_div</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></tt>
            </div>
            <div id="l227"
               class="code sev- "><tt><i>227</i>         <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span></tt>
            </div>
            <div id="l228"
               class="code sev- "><tt><i>228</i>             <span class="n">kl_div</span> <span class="o">=</span> <span class="n">kl_div</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></tt>
            </div>
            <div id="l229"
               class="code sev- "><tt><i>229</i>         <span class="c1"># else &#39;none&#39;: keep per-sample KL vector</span></tt>
            </div>
            <div id="l230"
               class="code sev- "><tt><i>230</i> &nbsp;</tt>
            </div>
            <div id="l231"
               class="code sev- "><tt><i>231</i>         <span class="c1"># Scale KL and add reconstruction</span></tt>
            </div>
            <div id="l232"
               class="code sev- "><tt><i>232</i>         <span class="k">return</span> <span class="n">recon_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="n">kl_div</span></tt>
            </div>
            <div id="l233"
               class="code sev- "><tt><i>233</i> &nbsp;</tt>
            </div>
            <div id="l234"
               class="code sev- "><tt><i>234</i> &nbsp;</tt>
            </div>
            <div id="l235"
               class="code sev- "><tt><i>235</i> <span class="k">class</span><span class="w"> </span><span class="nc">ELBOGaussianMixtureLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span></tt>
            </div>
            <div id="l236"
               class="code sev- "><tt><i>236</i> <span class="w">    </span><span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l237"
               class="code sev- "><tt><i>237</i> <span class="sd">    Gaussian Mixture VAE loss.</span></tt>
            </div>
            <div id="l238"
               class="code sev- "><tt><i>238</i> &nbsp;</tt>
            </div>
            <div id="l239"
               class="code sev- "><tt><i>239</i> <span class="sd">    Combines:</span></tt>
            </div>
            <div id="l240"
               class="code sev- "><tt><i>240</i> <span class="sd">      1) Entropy regularization:  -∑_i q(y=i|x) log q(y=i|x)</span></tt>
            </div>
            <div id="l241"
               class="code sev- "><tt><i>241</i> <span class="sd">      2) Reconstruction + KL:</span></tt>
            </div>
            <div id="l242"
               class="code sev- "><tt><i>242</i> <span class="sd">         - E_{q(y|x)} [ log p(x|z,y) ]</span></tt>
            </div>
            <div id="l243"
               class="code sev- "><tt><i>243</i> <span class="sd">         + E_{q(y|x)} [ KL( q(z|x,y) ‖ p(z|y) ) ]</span></tt>
            </div>
            <div id="l244"
               class="code sev- "><tt><i>244</i> <span class="sd">    &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l245"
               class="code sev- "><tt><i>245</i> &nbsp;</tt>
            </div>
            <div id="l246"
               class="code sev- "><tt><i>246</i>     <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">r_nent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span></tt>
            </div>
            <div id="l247"
               class="code sev- "><tt><i>247</i> <span class="w">        </span><span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l248"
               class="code sev- "><tt><i>248</i> <span class="sd">        Args:</span></tt>
            </div>
            <div id="l249"
               class="code sev- "><tt><i>249</i> <span class="sd">            k       Number of mixture components.</span></tt>
            </div>
            <div id="l250"
               class="code sev- "><tt><i>250</i> <span class="sd">            r_nent  Weight on the entropy term.</span></tt>
            </div>
            <div id="l251"
               class="code sev- "><tt><i>251</i> <span class="sd">        &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l252"
               class="code sev- "><tt><i>252</i>         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span></tt>
            </div>
            <div id="l253"
               class="code sev- "><tt><i>253</i>         <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span></tt>
            </div>
            <div id="l254"
               class="code sev- "><tt><i>254</i>         <span class="bp">self</span><span class="o">.</span><span class="n">r_nent</span> <span class="o">=</span> <span class="n">r_nent</span></tt>
            </div>
            <div id="l255"
               class="code sev- "><tt><i>255</i> &nbsp;</tt>
            </div>
            <div id="l256"
               class="code sev- "><tt><i>256</i>     <span class="nd">@staticmethod</span></tt>
            </div>
            <div id="l257"
               class="code sev- "><tt><i>257</i>     <span class="k">def</span><span class="w"> </span><span class="nf">log_normal</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l258"
               class="code sev- "><tt><i>258</i>                    <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l259"
               class="code sev- "><tt><i>259</i>                    <span class="n">var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l260"
               class="code sev- "><tt><i>260</i>                    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span></tt>
            </div>
            <div id="l261"
               class="code sev- "><tt><i>261</i> <span class="w">        </span><span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l262"
               class="code sev- "><tt><i>262</i> <span class="sd">        Compute log N(x; mu, var) summed over the last dim:</span></tt>
            </div>
            <div id="l263"
               class="code sev- "><tt><i>263</i> <span class="sd">          -½ ∑ [ log(2π) + (x−μ)^2 / var + log var ]</span></tt>
            </div>
            <div id="l264"
               class="code sev- "><tt><i>264</i> <span class="sd">        &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l265"
               class="code sev- "><tt><i>265</i>         <span class="n">const</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span></tt>
            </div>
            <div id="l266"
               class="code sev- "><tt><i>266</i>         <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span></tt>
            </div>
            <div id="l267"
               class="code sev- "><tt><i>267</i>             <span class="n">const</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="n">var</span><span class="o">.</span><span class="n">log</span><span class="p">(),</span></tt>
            </div>
            <div id="l268"
               class="code sev- "><tt><i>268</i>             <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span></tt>
            </div>
            <div id="l269"
               class="code sev- "><tt><i>269</i>         <span class="p">)</span></tt>
            </div>
            <div id="l270"
               class="code sev- "><tt><i>270</i> &nbsp;</tt>
            </div>
            <div id="l271"
               class="code sev- "><tt><i>271</i>     <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span></tt>
            </div>
            <div id="l272"
               class="code sev- "><tt><i>272</i>                 <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l273"
               class="code sev- "><tt><i>273</i>                 <span class="n">qy_logit</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span></tt>
            </div>
            <div id="l274"
               class="code sev- "><tt><i>274</i>                 <span class="n">xm_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span></tt>
            </div>
            <div id="l275"
               class="code sev- "><tt><i>275</i>                 <span class="n">xv_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span></tt>
            </div>
            <div id="l276"
               class="code sev- "><tt><i>276</i>                 <span class="n">z_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span></tt>
            </div>
            <div id="l277"
               class="code sev- "><tt><i>277</i>                 <span class="n">zm_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span></tt>
            </div>
            <div id="l278"
               class="code sev- "><tt><i>278</i>                 <span class="n">zv_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span></tt>
            </div>
            <div id="l279"
               class="code sev- "><tt><i>279</i>                 <span class="n">zm_prior_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span></tt>
            </div>
            <div id="l280"
               class="code sev- "><tt><i>280</i>                 <span class="n">zv_prior_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></tt>
            </div>
            <div id="l281"
               class="code sev- "><tt><i>281</i>                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span></tt>
            </div>
            <div id="l282"
               class="code sev- "><tt><i>282</i> <span class="w">        </span><span class="sd">&quot;&quot;&quot;</span></tt>
            </div>
            <div id="l283"
               class="code sev- "><tt><i>283</i> <span class="sd">        Args:</span></tt>
            </div>
            <div id="l284"
               class="code sev- "><tt><i>284</i> <span class="sd">            x                [batch, n_features]                Input data</span></tt>
            </div>
            <div id="l285"
               class="code sev- "><tt><i>285</i> <span class="sd">            qy_logit         [batch, k]                          Cluster logits</span></tt>
            </div>
            <div id="l286"
               class="code sev- "><tt><i>286</i> <span class="sd">            xm_list, xv_list length-k lists of [batch, n_features]</span></tt>
            </div>
            <div id="l287"
               class="code sev- "><tt><i>287</i> <span class="sd">            z_list, zm_list, zv_list       length-k lists of [batch, n_cvs]</span></tt>
            </div>
            <div id="l288"
               class="code sev- "><tt><i>288</i> <span class="sd">            zm_prior_list, zv_prior_list   length-k lists of [batch, n_cvs]</span></tt>
            </div>
            <div id="l289"
               class="code sev- "><tt><i>289</i> <span class="sd">        Returns:</span></tt>
            </div>
            <div id="l290"
               class="code sev- "><tt><i>290</i> <span class="sd">            scalar loss = mean_batch( r_nent*nent + ∑_i qy_i * [rec_i + KL_i] )</span></tt>
            </div>
            <div id="l291"
               class="code sev- "><tt><i>291</i> <span class="sd">        &quot;&quot;&quot;</span></tt>
            </div>
            <div id="l292"
               class="code sev- "><tt><i>292</i>         <span class="c1"># 1) cluster posteriors</span></tt>
            </div>
            <div id="l293"
               class="code sev- "><tt><i>293</i>         <span class="n">qy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">qy_logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># [batch, k]</span></tt>
            </div>
            <div id="l294"
               class="code sev- "><tt><i>294</i> &nbsp;</tt>
            </div>
            <div id="l295"
               class="code sev- "><tt><i>295</i>         <span class="c1"># 2) entropy regularization (cross-entropy of qy wrt itself)</span></tt>
            </div>
            <div id="l296"
               class="code sev- "><tt><i>296</i>         <span class="c1">#    nent = -E[ log q(y|x) ]</span></tt>
            </div>
            <div id="l297"
               class="code sev- "><tt><i>297</i>         <span class="n">nent</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">qy</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">qy_logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></tt>
            </div>
            <div id="l298"
               class="code sev- "><tt><i>298</i> &nbsp;</tt>
            </div>
            <div id="l299"
               class="code sev- "><tt><i>299</i>         <span class="c1"># 3) per-component reconstruction + KL</span></tt>
            </div>
            <div id="l300"
               class="code sev- "><tt><i>300</i>         <span class="n">comp_losses</span> <span class="o">=</span> <span class="p">[]</span></tt>
            </div>
            <div id="l301"
               class="code sev- "><tt><i>301</i>         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span></tt>
            </div>
            <div id="l302"
               class="code sev- "><tt><i>302</i>             <span class="c1"># reconstruction:  - log p(x | z_i)</span></tt>
            </div>
            <div id="l303"
               class="code sev- "><tt><i>303</i>             <span class="n">rec_i</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xm_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">xv_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span></tt>
            </div>
            <div id="l304"
               class="code sev- "><tt><i>304</i>             <span class="c1"># KL divergence:   KL( q(z|x,y=i) ‖ p(z|y=i) )</span></tt>
            </div>
            <div id="l305"
               class="code sev- "><tt><i>305</i>             <span class="n">kl_i</span> <span class="o">=</span> <span class="p">(</span></tt>
            </div>
            <div id="l306"
               class="code sev-2  le">
               <ul class="violations">
               
                  <li>
                     <span class="count sev-2">
                        W504
                     </span>
                     Line break after binary operator</li>
               
               </ul><tt><i>306</i>                 <span class="bp">self</span><span class="o">.</span><span class="n">log_normal</span><span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">zm_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">zv_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span></tt>
            </div>
            <div id="l307"
               class="code sev- "><tt><i>307</i>                 <span class="bp">self</span><span class="o">.</span><span class="n">log_normal</span><span class="p">(</span><span class="n">z_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">zm_prior_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">zv_prior_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span></tt>
            </div>
            <div id="l308"
               class="code sev- "><tt><i>308</i>             <span class="p">)</span></tt>
            </div>
            <div id="l309"
               class="code sev- "><tt><i>309</i>             <span class="n">comp_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rec_i</span> <span class="o">+</span> <span class="n">kl_i</span><span class="p">)</span>  <span class="c1"># shape [batch]</span></tt>
            </div>
            <div id="l310"
               class="code sev- "><tt><i>310</i> &nbsp;</tt>
            </div>
            <div id="l311"
               class="code sev- "><tt><i>311</i>         <span class="c1"># 4) weight each comp by qy[:,i] and sum</span></tt>
            </div>
            <div id="l312"
               class="code sev- "><tt><i>312</i>         <span class="n">weighted</span> <span class="o">=</span> <span class="p">[</span><span class="n">qy</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">comp_losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)]</span></tt>
            </div>
            <div id="l313"
               class="code sev- "><tt><i>313</i>         <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_nent</span> <span class="o">*</span> <span class="n">nent</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">weighted</span><span class="p">)</span>  <span class="c1"># shape [batch]</span></tt>
            </div>
            <div id="l314"
               class="code sev- "><tt><i>314</i> &nbsp;</tt>
            </div>
            <div id="l315"
               class="code sev- "><tt><i>315</i>         <span class="k">return</span> <span class="n">total</span><span class="p">,</span> <span class="n">nent</span></tt>
            </div>
            
         </div>
      </div>
   </body>
</html>